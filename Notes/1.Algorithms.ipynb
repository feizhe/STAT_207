{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76342784-d23a-41c6-b7cd-fdec882937fc",
   "metadata": {},
   "source": [
    "## STAT 207: Algorithms and Programs\n",
    "\n",
    "### Zhe Fei (zhe.fei@ucr.edu)\n",
    "\n",
    "- CS Chapters 2,3; NAS Chapter 1.\n",
    "\n",
    "### Algorithms\n",
    "\n",
    "Loosely speaking, algorithm is a method or a set of instructions for doing something.\n",
    "\n",
    "**How to cook fried rice**:\n",
    "\n",
    "1. **Prepare Ingredients:**  \n",
    "   Use pre-cooked, chilled rice; chop vegetables; beat eggs; and, if desired, cut protein into bite-sized pieces.\n",
    "\n",
    "2. **Heat the Oil:**  \n",
    "   Heat oil in a wok or pan and sauté garlic and ginger until fragrant.\n",
    "\n",
    "3. **Cook Protein & Eggs:**  \n",
    "   Stir-fry protein until cooked, then scramble eggs and set both aside.\n",
    "\n",
    "4. **Combine & Stir-Fry:**  \n",
    "   Add vegetables to the pan, then stir in rice. Return protein and eggs, and season with soy sauce, salt, and pepper.\n",
    "\n",
    "5. **Serve:**  \n",
    "   Garnish with green onions or sesame seeds and serve hot.\n",
    "\n",
    "\n",
    "**Algorithms** are sometimes distinguished as\n",
    "\n",
    "- Numerical\n",
    "\n",
    "- Seminumerical\n",
    "\n",
    "- Nonnumerical\n",
    "\n",
    "**Program** is a set of computer instructions that implement the algorithm.\n",
    "\n",
    "- A poor implementation can render a good algorithm useless. \n",
    "\n",
    "- A good implementation will preserve the algorithm’s accuracy and efficiency, and will detect data that are inappropriate for the algorithm. \n",
    "\n",
    "A robust algorithm is applicable over a wide range of data to which it is applicable. \n",
    "\n",
    "A robust program, which is more important, is one that will detect input data that are inappropriate\n",
    "either for the algorithm or for the implementation in the given program.\n",
    "\n",
    "\n",
    "Two most important aspects of a computer algorithm:\n",
    "\n",
    "- **Accuracy**\n",
    "\n",
    "- **Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235c638-9ea2-4e1c-a64c-a554c948ea8e",
   "metadata": {},
   "source": [
    "#### Error in Numerical Computations\n",
    "\n",
    "The basic source of error in numerical computations is the inability to work with the reals.\n",
    "\n",
    "- absolute error, $|\\widetilde{r} -r|$\n",
    "\n",
    "- relative error, $|\\widetilde{r} -r|/|r|$\n",
    "\n",
    "What if $r$ is not a single real number? For example, in statistical data analysis, the\n",
    "numerical result, $\\widetilde{r}$, may consist of estimates of several regression coefficients,\n",
    "various sums of squares and their ratio, and several other quantities.\n",
    "\n",
    "$$\n",
    "\\Delta(\\widetilde{r}, r),\n",
    "$$\n",
    "where $\\Delta(\\cdot, \\cdot)$ is a nonnegative, real-valued function.\n",
    "\n",
    "If $r$ is a vector, the measure may be based on some norm, $\\|\\widetilde{r} -r \\|$.\n",
    "\n",
    "\n",
    "- For a given algorithm, the amount of error to expect or  some bound on the error. \n",
    "\n",
    "- Alternatively, an upper bound on the error. \n",
    "\n",
    "- Or, an estimate of an “average error” based on some assumed probability distribution of the data comprising the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51665de0-2e1e-4d0c-b618-9a4e3e06815e",
   "metadata": {},
   "source": [
    "#### Order of Error\n",
    "\n",
    "In general, a function $f(t)$ is said to be of order $g(t)$ at $t_0$, written $O(g(t))$ (\"big O of $g(t)$\"), if there exists a positive constant $M$ such that\n",
    "$$\n",
    "|f(t)| \\le M|g(t)| \\quad \\text{as } t\\rightarrow t_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea28193-7866-4f1e-ba32-465b5bd610cf",
   "metadata": {},
   "source": [
    "This is the order of convergence of one function to another function at a given\n",
    "point. Notice that this is pointwise convergence; we compare the functions\n",
    "near the point $t_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd410a85-0779-496f-8037-8bea87ab30a3",
   "metadata": {},
   "source": [
    "For example, if $\\widetilde{f}(t)$ is a finite series approximation to $f(t)$ using $k$ terms, we may express the error as $O(h(k))$ for some function $h(k)$. Typical orders of errors due to the approximation may be\n",
    "\n",
    "- $O(1/k)$\n",
    "\n",
    "- $O(1/k^2)$\n",
    "\n",
    "- $O(1/k!)$\n",
    "\n",
    "**Sample Mean**: Say $E(X) = \\mu$, the mean estimate of $n$ samples is $\\widehat{\\mu} = (\\sum_i X_i)/n$, and the order of error $|\\widehat{\\mu} - \\mu|$ is?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bfac4-6dc1-4e11-82f9-0228415c2ce2",
   "metadata": {},
   "source": [
    "The special case of convergence to the constant zero is often of interest. A\n",
    "function $f(t)$ is said to be \"little o of $g(t)$\" at $t_0$, written $o(g(t))$, if\n",
    "$$\n",
    "f(t)/g(t)\\rightarrow 0, \\quad \\text{as } t\\rightarrow t_0.\n",
    "$$\n",
    "If the function $f(t)$ approaches $0$ at $t_0$, $g(t)$ can be taken as a constant and\n",
    "$f(t)$ is said to be $o(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006ebfc",
   "metadata": {},
   "source": [
    "A function $f(t)$ is said to be $\\Omega(g(t))$ (“big omega of $g(t)$”) if there exists a positive constant $m$\n",
    "such that\n",
    "$$\n",
    "|f(t)| \\ge m|g(t)| \\quad \\text{as } t\\rightarrow t_0.\n",
    "$$\n",
    "Likewise, a function $f(t)$ is said to be “little omega of $g(t)$” at $t_0$, written $\\omega(g(t))$, if\n",
    "$$\n",
    "g(t)/f(t) \\rightarrow 0, \\quad \\text{as } t\\rightarrow t_0.\n",
    "$$\n",
    "\n",
    "Usually the limit on $t$, that is, $t_0$, in order expressions is either 0 or $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c4bb0",
   "metadata": {},
   "source": [
    "### Algorithms and Data\n",
    "\n",
    "The performance of an algorithm may depend on the data.\n",
    "\n",
    "Heuristically, data for a given problem are ill-conditioned if small changes in the data may yield large changes in the solution.\n",
    "\n",
    "- Condition of Data: quantify the condition of a dataset by **condition number**.\n",
    "\n",
    "- Robustness of Algorithms: handle a wide range of inputs; manage errors or irregularities in the data.\n",
    "\n",
    "- Stability of Algorithms: stable results to small errors or perturbations.\n",
    "\n",
    "\n",
    "### Efficiency\n",
    "\n",
    "The efficiency of an algorithm refers to its usage of computer resources:\n",
    "\n",
    "- processing units (CPU, GPU, TPU, etc) \n",
    "\n",
    "- memory (storage)\n",
    "\n",
    "A limiting factor for the time the processing units are in use is the number\n",
    "and type of operations required.\n",
    "\n",
    "In numerical computations, the most important types of computation are\n",
    "usually the **floating-point operations**. The actual number of floating-point operations\n",
    "divided by the number of seconds required to perform the operations\n",
    "is called the **flops (floating-point operations per second)** rate.\n",
    "\n",
    "- **Intel Core i9-14900K:** reach up to around 4 TFLOP (teraflops) in single-precision floating-point (FP32) performance.\n",
    "\n",
    "- **Apple's M2:** 3.55 TFLOPs\n",
    "\n",
    "- **NVIDIA GeForce RTX 4090:** 82.6 TFLOPS in FP32 performance.\n",
    "\n",
    "- **NVIDIA H100 Tensor Core GPU:** Designed for data centers and AI applications, the H100 delivers up to 34 TFLOPS in double-precision (FP64), around 67 TFLOPS in FP32, and up to 1,000 TFLOPS for tensor operations used in AI and deep learning. \n",
    "\n",
    "#### Measuring Efficiency\n",
    "\n",
    "Often, instead of the exact number of operations, we use the *order* of the\n",
    "number of operations in terms of the measure of problem size. \n",
    "\n",
    "If $n$ is some measure of the size of the problem, an algorithm has order $O(f(n))$ if, as\n",
    "$n \\rightarrow \\infty$, the number of computations $\\rightarrow cf(n)$, where $c$ is some constant\n",
    "that does not depend on $n$. \n",
    "\n",
    "- to multiply two $n \\times n$ matrices in the obvious way requires $O(n^3)$ multiplications and additions; \n",
    "\n",
    "- to multiply an $n \\times m$ matrix and an $m \\times p$ matrix requires $O(nmp)$ multiplications and additions. \n",
    "\n",
    "In the latter case, $n, m$, and $p$ are all measures of the size of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021459e",
   "metadata": {},
   "source": [
    "### Recursion \n",
    "\n",
    "Recurrence relations are ubiquitous in computational statistics and probability.\n",
    "\n",
    "**Binomial Coefficients**\n",
    "\n",
    "Let ${n \\choose k}$ be the number of subsets of size $k$ from a set of size $n$. Pascal's triangle is the recurrence scheme specified by\n",
    "$$\n",
    "{n+1 \\choose k} = {n \\choose k-1} + {n \\choose k},\n",
    "$$\n",
    "with the boundary conditions ${n \\choose 0} = {n \\choose n} =1$.\n",
    "\n",
    "\n",
    "**Number of Partitions of a Set**\n",
    "\n",
    "\n",
    "\n",
    "Let $B_n$ be the number of partitions of a set with $n$ elements. By a partition we mean a division of the set into disjoint blocks.\n",
    "\n",
    "Starting with $B_0 = 1$, the $B_n$ satisfy the recurrence relation\n",
    "$$\n",
    "\\begin{aligned}\n",
    "B_{n+1} =& \\sum_{k=0}^{n} {n \\choose k} B_{n-k} \\\\\n",
    "=& \\sum_{k=0}^{n} {n \\choose k} B_{k}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Horner’s Method**\n",
    "\n",
    "Suppose we want to evaluate the polynomial \n",
    "$$\n",
    "p(x) = a_0 x^n + a_1 x^{n-1} + ... +a_{n-1} x + a_n\n",
    "$$\n",
    "for a particular value of x. A naive alrogithm would require $3n-1$ operations. On the other hand, we can write\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(x) =& x(a_0 x^{n-1} + a_1 x^{n-2} + ... +a_{n-1}) + a_n\\\\\n",
    "=& xb_{n-1}(x) + a_n.\n",
    "\\end{aligned}\n",
    "$$\n",
    "And do the same for $b_{n-1}(x)$, a complete recursive scheme is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "b_0(x) =& a_0\\\\\n",
    "b_k(x) =& xb_{k-1}(x) + a_k, \\quad k=1,2,..,n.\n",
    "\\end{aligned}\n",
    "$$\n",
    "This scheme, known as Horner’s method, requires only $n$ multiplications\n",
    "and $n$ additions to compute $p(x) = b_n(x)$.\n",
    "\n",
    "- Horner’s method can be modified to produce the derivative $p'(x)$ as well as $p(x)$. This modification is useful, for instance, in searching for a root of $p(x)$ by Newton’s method.\n",
    "\n",
    "\n",
    "**An Unstable Recurrence**\n",
    "\n",
    "Not all recurrence relations are numerically stable. Consider the integrals\n",
    "$$\n",
    "y_n = \\int_0^1 \\frac{x^n}{x+a}dx.\n",
    "$$\n",
    "The recurrence can be derived as \n",
    "$$\n",
    "y_n = 1/n - ay_{n-1}.\n",
    "$$\n",
    "With the initial value $y_0 = \\ln\\frac{1+a}{a}$. We can compute the sequence with certain precision as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4c479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_0 = 0.0953\n",
      "y_1 = 0.0469\n",
      "y_2 = 0.0310\n",
      "y_3 = 0.0233\n",
      "y_4 = 0.0167\n",
      "y_5 = 0.0330\n",
      "y_6 = -0.1633\n",
      "y_7 = 1.7762\n",
      "y_8 = -17.6366\n",
      "y_9 = 176.4771\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "a = 10\n",
    "y = math.log((1+a)/a)\n",
    "\n",
    "print(f\"y_0 = {y:.4f}\")\n",
    "\n",
    "for n in range(1, 10):\n",
    "    y = 1/n - a*round(y,5)\n",
    "    print(f\"y_{n} = {y:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecfff0c",
   "metadata": {},
   "source": [
    "For $n$ moderately large, most of the mass of the integral occurs near $x=1$. Thus, to a good approximation\n",
    "$$\n",
    "y_{n-1} \\approx \\frac{1}{1+a}\\int_0^1 x^{n-1}dx = \\frac{1}{(1+a)n}.\n",
    "$$\n",
    "And \n",
    "$$\n",
    "y_{n} \\approx \\frac{1}{n} - a \\frac{1}{(1+a)n} = \\frac{1}{n}\\left( 1 - \\frac{a}{1+a} \\right).\n",
    "$$\n",
    "We lose precision whenever we subtract two numbers of the\n",
    "same sign and comparable magnitude. \n",
    "\n",
    "- We must exercise caution in using recurrence relations involving subtraction. \n",
    "\n",
    "- Fortunately, many recurrences in probability theory arise by conditioning argumentsand consequently entail only addition and multiplication of nonnegative numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6b629",
   "metadata": {},
   "source": [
    "### Improving Efficiency\n",
    "\n",
    "There are many ways to attempt to improve the efficiency of an algorithm, a brief overview here:\n",
    "\n",
    "- Divide and Conquer: *NAS 1.10 Quick Sort Algorithm*\n",
    "\n",
    "- Convolutions: If $f$ and $g$ are PDFs of stochastically independent random variables $U$ and $V$, then $f*g$ is the PDF of $U+V$.\n",
    "\n",
    "- Discrete Transforms: discrete Fourier transform (DFT), fast Fourier Transform (FFT). Widely used in signal processing, image processing, etc.\n",
    "\n",
    "- Greedy Methods: design each step to be as efficient as possible, without regard to what future steps may be part of the algorithm.\n",
    "\n",
    "\n",
    "### Iterations and Convergence\n",
    "\n",
    "- “Iterative” algorithms are methods in which groups of computations form successive approximations to the desired solution.\n",
    "\n",
    "- “Converge”, and the various derivatives of this root word, refers to a condition in the progress of an algorithm in which the values no longer change.\n",
    "\n",
    "- Convergence criterion or stopping criterion:\n",
    "$$\n",
    "\\Delta(x^{(k)}, x^{(k-1)}) \\le \\epsilon.\n",
    "$$\n",
    "\n",
    "\n",
    "There are typically three reasons to terminate an algorithm.\n",
    "\n",
    "- It is known that the problem is solved.\n",
    "\n",
    "- The iterations converge, that is, the computed values quit changing.\n",
    "\n",
    "- The number of iterations is too large, or the problem appears to diverge.\n",
    "\n",
    "\n",
    "#### Rate of Convergence\n",
    "\n",
    "The *convergence ratio* of the sequence $x^{(k)}$ to a constant $x_0$ is\n",
    "$$\n",
    "\\lim_{k \\rightarrow \\infty} \\frac{\\Delta(x^{(k+1)}, x_0)}{\\Delta(x^{(k)}, x_0)}\n",
    "$$\n",
    "if this limit exists.\n",
    "\n",
    "- If the convergence ratio is greater than 0 and less than 1, the sequence is said to converge *linearly*. \n",
    "\n",
    "- If the convergence ratio is 0, the sequence is said to converge *superlinearly*.\n",
    "\n",
    "- The convergence rate is often a function of $k$, say $g(k)$. The convergence is then expressed as an order in $k$, $O(g(k))$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8667e",
   "metadata": {},
   "source": [
    "### Programming\n",
    "\n",
    "\"Programming is only learned by programming.\" - Gentle, *Computational Statistics*\n",
    "\n",
    "\n",
    "High-level languages for readily implementations:\n",
    "\n",
    "- R: `tidyverse`, `ggplot`\n",
    "\n",
    "- Matlab\n",
    "\n",
    "- Python: `numpy`, `sklearn`\n",
    "\n",
    "Low-level languages when developing new algorithms:\n",
    "\n",
    "- Rcpp\n",
    "\n",
    "- Cython\n",
    "\n",
    "- Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6d5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat_207",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
